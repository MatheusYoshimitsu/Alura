{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta aula, provavelmente será necessário usar GPU para facilitar as coisas. Provavelmente o ambiente será migrado para o Colab. No entanto, começarei fazendo aqui para ver como é o desempenho da CPU e ao final, apenas importo o arquivo .ipynb para o Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim # nn possui as funcoes de perda, optim os otimizadores\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Criando um dicionario\n",
    "args = {\n",
    "    'batch_size': 500,\n",
    "    'num_workers': 4, # numero de threads\n",
    "    'lr': 1e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "    'num_epochs': 30 \n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args['device'] = torch.device('cuda')\n",
    "else:\n",
    "    args['device'] = torch.device('cpu')\n",
    "\n",
    "print(args['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amostras de treino: 60000\n",
      "Amostras de teste: 10000\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.MNIST('./',\n",
    "                           train = True,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           # transform = transforms.RandomCrop(12),\n",
    "                           download = True)\n",
    "test_set = datasets.MNIST('./',\n",
    "                           train = False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           download = False)\n",
    "\n",
    "print('Amostras de treino: ' + str(len(train_set)) + '\\nAmostras de teste: ' + str(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'> <class 'torchvision.datasets.mnist.MNIST'>\n",
      "<class 'tuple'> <class 'tuple'>\n",
      "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
      "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
      "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
      "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
      "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
      "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
      "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
      "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
      "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
      "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
      "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
      "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
      "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
      "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
      "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
      "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000]]]), 5)\n"
     ]
    }
   ],
   "source": [
    "# Quando formos trabalhar com datasets proprios, teremos que implementar classes especificas dessa mesma forma\n",
    "print(type(train_set), type(test_set))\n",
    "print(type(train_set[0]), type(test_set[0]))\n",
    "\n",
    "# Sempre sera uma tupla(dado, rotulo)\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"140523292149312process_stream_events\"\n",
      "    while executing\n",
      "\"140523292149312process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command: application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    dado, rotulo = train_set[i]\n",
    "    # dado, rotulo = train_set[0]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(dado[0])\n",
    "    # plt.imshow(dado)\n",
    "    plt.title('Rotulo' + str(rotulo))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args['batch_size'], shuffle=True, num_workers=args['num_workers'])\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size=args['batch_size'], shuffle=True, num_workers=args['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 28, 28]) torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "# Iterador, mas nao suporta indexacao\n",
    "for batch in train_loader:\n",
    "    dado, rotulo = batch\n",
    "    print(dado.size(), rotulo.size())\n",
    "\n",
    "    plt.imshow(dado[0][0])\n",
    "    plt.title('Rotulo: ' + str(rotulo[0]))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, out_size):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "                            nn.Linear(input_size, hidden_size),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size, hidden_size),\n",
    "                            nn.ReLU()\n",
    "                        )\n",
    "        self.out = nn.Linear(hidden_size, out_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward (self, X):\n",
    "\n",
    "        X = X.view(X.size(0), -1)\n",
    "\n",
    "        feature = self.features(X)\n",
    "        output = self.softmax(self.out(feature))\n",
    "\n",
    "        return output\n",
    "    \n",
    "input_size = 28 * 28\n",
    "hidden_size = 128 # numero escolhido arbitrariamente\n",
    "out_size = 10 # numero de classes\n",
    "\n",
    "net = MLP(input_size, hidden_size, out_size).to(args['device']) # cast na GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(args['device'])\n",
    "optimizer = optim.Adam(net.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca: 0, Loss: 2.2302 +\\- 0.0734\n",
      "Epoca: 1, Loss: 1.9293 +\\- 0.0675\n",
      "Epoca: 2, Loss: 1.8043 +\\- 0.0309\n",
      "Epoca: 3, Loss: 1.7336 +\\- 0.0217\n",
      "Epoca: 4, Loss: 1.6968 +\\- 0.0285\n",
      "Epoca: 5, Loss: 1.6880 +\\- 0.0214\n",
      "Epoca: 6, Loss: 1.6356 +\\- 0.0194\n",
      "Epoca: 7, Loss: 1.6185 +\\- 0.0167\n",
      "Epoca: 8, Loss: 1.6090 +\\- 0.0174\n",
      "Epoca: 9, Loss: 1.5968 +\\- 0.0135\n",
      "Epoca: 10, Loss: 1.5798 +\\- 0.0154\n",
      "Epoca: 11, Loss: 1.5800 +\\- 0.0132\n",
      "Epoca: 12, Loss: 1.5741 +\\- 0.0150\n",
      "Epoca: 13, Loss: 1.5694 +\\- 0.0128\n",
      "Epoca: 14, Loss: 1.5623 +\\- 0.0128\n",
      "Epoca: 15, Loss: 1.5593 +\\- 0.0119\n",
      "Epoca: 16, Loss: 1.5554 +\\- 0.0136\n",
      "Epoca: 17, Loss: 1.5538 +\\- 0.0119\n",
      "Epoca: 18, Loss: 1.5519 +\\- 0.0136\n",
      "Epoca: 19, Loss: 1.5474 +\\- 0.0130\n",
      "Epoca: 20, Loss: 1.5474 +\\- 0.0133\n",
      "Epoca: 21, Loss: 1.5459 +\\- 0.0131\n",
      "Epoca: 22, Loss: 1.5410 +\\- 0.0120\n",
      "Epoca: 23, Loss: 1.5391 +\\- 0.0107\n",
      "Epoca: 24, Loss: 1.5409 +\\- 0.0121\n",
      "Epoca: 25, Loss: 1.5395 +\\- 0.0112\n",
      "Epoca: 26, Loss: 1.5392 +\\- 0.0115\n",
      "Epoca: 27, Loss: 1.5386 +\\- 0.0137\n",
      "Epoca: 28, Loss: 1.5360 +\\- 0.0113\n",
      "Epoca: 29, Loss: 1.5330 +\\- 0.0113\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args['num_epochs']):\n",
    "\n",
    "    epoch_loss = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        dado, rotulo = batch\n",
    "        dado = dado.to(args['device'])\n",
    "        rotulo = rotulo.to(args['device'])\n",
    "\n",
    "        # Forward\n",
    "        pred = net(dado)\n",
    "        loss = criterion(pred, rotulo)\n",
    "        epoch_loss.append(loss.cpu().data)\n",
    "\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = np.asarray(epoch_loss)\n",
    "\n",
    "    print(\"Epoca: %d, Loss: %.4f +\\- %.4f\" % (epoch, epoch_loss.mean(), epoch_loss.std()))\n",
    "\n",
    "# batch_size: 20\n",
    "# Aproximadamente 30 segundos entre a epoca 3 e 4.\n",
    "# 2 minutos e 37 segundos para 4 epocas\n",
    "# Epocas para loss abaixo de 1.6: mesmo apos 11 epocas (5 min 43 s), o desvio padrao foi diminuindo e a media aumentando\n",
    "\n",
    "# batch_size: 100\n",
    "# Epocas para loss abaixo de 1.6: epocas finalizadas em 29 (0 - 29), nao ficou abaixo de 1.6\n",
    "# 3 min e 50 segundos para 30 epocas\n",
    "\n",
    "# batch_size: 5\n",
    "# Epocas para loss abaixo de 1.6: mesmo apos 2 epocas (5 min 54 s), a media foi aumentando\n",
    "# 5 min e 54 segundos para 3 epocas (0 - 2)     \n",
    "\n",
    "# Percebe-se pelas notas da professora, que usando a GPU, o tempo mais rapido foi de 5 segundos por epoca e o mais lento de 38 segundos por epoca. Diferentemente da CPU local, que o mais rapido foi de quase 7,6 segundos por epoca e o mais lento de 118 segundos por epoca\n",
    "\n",
    "# Apenas com batch_size: 500, que finalmente foi possivel ter uma loss abaixo de 1.6, demorando 9 epocas. Ao rodar as 30 epocas em 2 min 40 s, temos uma media de 5.3 s por epoca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
